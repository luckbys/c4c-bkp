# Plano de Implementa√ß√£o de Agentes de IA para Gest√£o de Conversas de Tickets

## √çndice

1. [Vis√£o Geral do Projeto](#1-vis√£o-geral-do-projeto)
2. [Pr√©-requisitos e Depend√™ncias](#2-pr√©-requisitos-e-depend√™ncias)
3. [An√°lise da Plataforma Evo AI](#3-an√°lise-da-plataforma-evo-ai)
4. [Arquitetura do Sistema](#4-arquitetura-do-sistema)
5. [Especifica√ß√£o dos Agentes](#5-especifica√ß√£o-dos-agentes)
6. [Integra√ß√£o com Sistema Existente](#6-integra√ß√£o-com-sistema-existente)
7. [Configura√ß√£o T√©cnica](#7-configura√ß√£o-t√©cnica)
8. [Exemplos de C√≥digo](#8-exemplos-de-c√≥digo)
9. [Cronograma de Implementa√ß√£o](#9-cronograma-de-implementa√ß√£o)
10. [Deployment e Infraestrutura](#10-deployment-e-infraestrutura)
11. [Monitoramento e M√©tricas](#11-monitoramento-e-m√©tricas)
12. [Casos de Uso Pr√°ticos](#12-casos-de-uso-pr√°ticos)
13. [Troubleshooting e FAQ](#13-troubleshooting-e-faq)
14. [Considera√ß√µes de Escalabilidade](#14-considera√ß√µes-de-escalabilidade)
15. [Roadmap Futuro](#15-roadmap-futuro)

***

## 1. Vis√£o Geral do Projeto

### 1.1 Objetivo

Implementar um sistema de agentes de IA utilizando a plataforma Evo AI para automatizar e otimizar o atendimento ao cliente atrav√©s de conversas inteligentes em tickets do sistema CRM.

### 1.2 Benef√≠cios Esperados

* **Redu√ß√£o de 60%** no tempo de resposta inicial

* **Resolu√ß√£o autom√°tica de 40%** dos tickets b√°sicos

* **Disponibilidade 24/7** para atendimento

* **Melhoria na satisfa√ß√£o do cliente** (meta: +25% NPS)

* **Otimiza√ß√£o da carga de trabalho** dos agentes humanos

* **Redu√ß√£o de custos operacionais** em at√© 35%

* **Escalabilidade autom√°tica** durante picos de demanda

### 1.3 Escopo do Projeto Simplificado

* **Integra√ß√£o** com sistema CRM existente (Firebase + Evolution API)
* **Desenvolvimento** de um agente LLM principal
* **Implementa√ß√£o** de processamento direto e inteligente
* **Configura√ß√£o** de monitoramento b√°sico
* **Treinamento** da equipe de suporte
* **Documenta√ß√£o** completa do sistema
* **Base** para expans√£o futura com m√∫ltiplos agentes

### 1.4 Stakeholders

* **Equipe de Desenvolvimento**: Implementa√ß√£o t√©cnica

* **Equipe de Suporte**: Usu√°rios finais do sistema

* **Ger√™ncia de TI**: Aprova√ß√£o e recursos

* **Clientes**: Benefici√°rios finais do atendimento melhorado

***

## 2. Pr√©-requisitos e Depend√™ncias

### 2.1 Infraestrutura Necess√°ria

#### Backend

* **Python**: 3.10 ou superior

* **PostgreSQL**: 13.0 ou superior

* **Redis**: 6.0 ou superior

* **Docker**: Para containeriza√ß√£o

* **Git**: Para controle de vers√£o

* **Make**: Para automa√ß√£o de comandos

#### Frontend

* **Node.js**: 18.0 ou superior

* **pnpm**: Gerenciador de pacotes (recomendado)

* **Next.js**: 15.0 (j√° instalado no projeto)

### 2.2 Recursos de Hardware

#### Ambiente de Desenvolvimento

* **CPU**: 4 cores m√≠nimo

* **RAM**: 8GB m√≠nimo

* **Armazenamento**: 50GB SSD

* **Rede**: Conex√£o est√°vel para APIs externas

#### Ambiente de Produ√ß√£o

* **CPU**: 8 cores recomendado

* **RAM**: 16GB m√≠nimo

* **Armazenamento**: 200GB SSD

* **Backup**: Estrat√©gia de backup automatizada

### 2.3 Chaves de API Necess√°rias

* **OpenAI API Key**: Para modelos GPT-4/GPT-3.5

* **Gemini API Key**: Para Google Gemini (alternativa)

* **Langfuse Keys**: Para observabilidade

* **Firebase Service Account**: Para integra√ß√£o

* **Evolution API Key**: Para WhatsApp

### 2.4 Permiss√µes e Acessos

* **Firebase Admin**: Acesso completo ao Firestore

* **Evolution API**: Permiss√µes de webhook

* **Redis**: Acesso de leitura/escrita

* **PostgreSQL**: Permiss√µes de DDL/DML

***

## 3. An√°lise da Plataforma Evo AI

### 3.1 Caracter√≠sticas Principais

A **Evo AI** √© uma plataforma open-source que oferece:

* **7 tipos de agentes** diferentes para casos espec√≠ficos

* **Protocolo A2A** (Agent-to-Agent) do Google

* **LangGraph** para workflows complexos

* **Integra√ß√£o nativa** com Langfuse

* **Gerenciamento seguro** de chaves API

* **Interface visual** para cria√ß√£o de workflows

### 3.2 Agente LLM (Language Model)

#### 3.2.1 Agente Principal

* **Descri√ß√£o**: Agente √∫nico baseado em modelos de linguagem

* **Modelos suportados**: GPT-4, GPT-3.5-turbo, Claude, Gemini

* **Configura√ß√µes**: Prompts din√¢micos, temperatura ajust√°vel, max tokens

* **Funcionalidades**:
  - Classifica√ß√£o autom√°tica de tickets
  - Respostas contextuais baseadas em conhecimento
  - Escala√ß√£o inteligente quando necess√°rio
  - Follow-up autom√°tico

#### 3.2.2 Capacidades do Agente

* **Processamento de linguagem natural** para entender contexto
* **Base de conhecimento integrada** para respostas precisas
* **Sistema de prompts configur√°vel** para diferentes cen√°rios
* **Integra√ß√£o direta** com Firebase e Evolution API
* **Logs detalhados** para monitoramento e melhoria cont√≠nua

* **Funcionalidade**: Itera√ß√µes com limite m√°ximo

* **Uso no projeto**: Follow-up autom√°tico

#### 3.2.6 Workflow Agent

* **Descri√ß√£o**: Workflows customizados com LangGraph

* **Funcionalidade**: Estrutura de grafo complexa

* **Uso no projeto**: Orquestra√ß√£o geral do sistema

#### 3.2.7 Task Agent

* **Descri√ß√£o**: Executa tarefas espec√≠ficas

* **Funcionalidade**: Instru√ß√µes estruturadas

* **Uso no projeto**: Tarefas espec√≠ficas como categoriza√ß√£o

### 3.3 Stack Tecnol√≥gico

#### Backend

* **FastAPI**: Framework web para API

* **SQLAlchemy**: ORM para intera√ß√£o com banco

* **PostgreSQL**: Banco de dados principal

* **Alembic**: Sistema de migra√ß√£o

* **Pydantic**: Valida√ß√£o e serializa√ß√£o

* **Uvicorn**: Servidor ASGI

* **Redis**: Cache e gerenciamento de sess√£o

* **JWT**: Autentica√ß√£o segura

* **LangGraph**: Framework para workflows

#### Frontend

* **Next.js 15**: Framework React

* **React 18**: Biblioteca de interface

* **TypeScript**: JavaScript tipado

* **Tailwind CSS**: Framework CSS

* **shadcn/ui**: Biblioteca de componentes

* **ReactFlow**: Workflows visuais

* **React Query**: Gerenciamento de estado

***

## 4. Arquitetura do Sistema

### 4.1 Diagrama de Arquitetura Simplificada

```mermaid
graph TB
    subgraph "Cliente"
        WA[WhatsApp]
        WEB[Interface Web]
    end
    
    subgraph "API Gateway"
        EVO[Evolution API]
        CRM[CRM API]
    end
    
    subgraph "Evo AI Platform"
        LLM[Agente LLM Principal]
    end
    
    subgraph "Dados"
        FB[Firebase]
        KB[Base de Conhecimento]
    end
    
    subgraph "Observabilidade"
        LF[Langfuse]
        MT[M√©tricas]
    end
    
    WA --> EVO
    WEB --> CRM
    EVO --> LLM
    CRM --> LLM
    
    LLM --> FB
    LLM --> KB
    
    LLM --> LF
    LLM --> MT
```

### 4.2 Fluxo de Dados Simplificado

#### 4.2.1 Fluxo Principal de Processamento

1. **Cliente** envia mensagem via WhatsApp
2. **Evolution API** recebe e processa
3. **Webhook** dispara evento para CRM
4. **Agente LLM** recebe e analisa a mensagem
5. **Agente LLM** classifica automaticamente (categoria/prioridade)
6. **Agente LLM** consulta base de conhecimento
7. **Agente LLM** gera resposta contextual
8. **Resposta** enviada ao cliente via Evolution API
9. **Logs** salvos no Firebase para monitoramento

#### 4.2.2 Fluxo de Escala√ß√£o Autom√°tica

1. **Agente LLM** identifica caso complexo ou alta prioridade
2. **Sistema** marca ticket para escala√ß√£o
3. **Notifica√ß√£o** autom√°tica para agente humano
4. **Contexto completo** transferido no Firebase
5. **Monitoramento** de SLA ativado

### 4.3 Componentes de Integra√ß√£o

#### 4.3.1 Firebase Integration

* **Firestore**: Armazenamento de tickets e mensagens

* **Real-time**: Sincroniza√ß√£o em tempo real

* **Authentication**: Autentica√ß√£o de usu√°rios

* **Cloud Functions**: Processamento serverless

#### 4.3.2 Evolution API Integration

* **Webhooks**: Eventos de mensagens

* **Send Message**: Envio de respostas

* **Media Handling**: Processamento de m√≠dia

* **Status Updates**: Atualiza√ß√µes de status

#### 4.3.3 Redis Integration

* **Session Management**: Gerenciamento de sess√µes

* **Cache**: Cache de respostas frequentes

* **Queue**: Fila de processamento

* **Rate Limiting**: Controle de taxa

***

## 5. Especifica√ß√£o do Agente LLM

### 5.1 Agente LLM Principal

#### 5.1.1 Responsabilidades Integradas

* **An√°lise** completa de conte√∫do da mensagem
* **Classifica√ß√£o** autom√°tica por categoria e prioridade
* **Gera√ß√£o** de respostas contextuais
* **Consulta** √† base de conhecimento
* **Decis√£o** de escala√ß√£o quando necess√°rio
* **Follow-up** autom√°tico baseado em regras

#### 5.1.2 Configura√ß√£o do Agente

```json
{
  "name": "AgenteLLMPrincipal",
  "type": "llm",
  "model": "gpt-4",
  "temperature": 0.3,
  "max_tokens": 1000,
  "system_prompt": "Voc√™ √© um assistente de atendimento ao cliente especializado...",
  "functions": [
    "classify_message",
    "search_knowledge_base",
    "generate_response",
    "check_escalation_criteria"
  ]
}
```

#### 5.1.3 Categorias de Classifica√ß√£o

* **T√©cnico**: Problemas de funcionamento
* **Comercial**: Quest√µes de vendas/cobran√ßa
* **Suporte**: D√∫vidas de uso
* **Reclama√ß√£o**: Insatisfa√ß√£o com servi√ßo
* **Elogio**: Feedback positivo

#### 5.1.4 N√≠veis de Prioridade

* **Cr√≠tica**: Sistema fora do ar
* **Alta**: Funcionalidade importante afetada
* **M√©dia**: Problema que pode aguardar
* **Baixa**: D√∫vidas gerais

#### 5.1.5 Base de Conhecimento Integrada

* **FAQ**: Perguntas frequentes e respostas padr√£o
* **Procedimentos**: Guias passo-a-passo para resolu√ß√£o
* **Pol√≠ticas**: Regras da empresa e termos de servi√ßo
* **Contatos**: Informa√ß√µes de contato e escala√ß√£o
* **Hist√≥rico**: Intera√ß√µes anteriores do cliente

#### 5.1.6 Crit√©rios de Escala√ß√£o Autom√°tica

* **Complexidade t√©cnica** alta (palavras-chave espec√≠ficas)
* **Cliente VIP** ou premium (identifica√ß√£o autom√°tica)
* **Problema recorrente** (3+ intera√ß√µes sobre o mesmo assunto)
* **Sentimento negativo** detectado na mensagem
* **Tempo limite** excedido (> 5 minutos sem resolu√ß√£o)

#### 5.1.7 Sistema de Prompts Din√¢micos

```json
{
  "prompts": {
    "classification": "Analise esta mensagem e classifique por categoria e prioridade...",
    "response_generation": "Com base no contexto e na base de conhecimento, gere uma resposta √∫til...",
    "escalation_check": "Avalie se este caso precisa ser escalado para um agente humano...",
    "follow_up": "Determine se √© necess√°rio agendar um follow-up para este cliente..."
  }
}
```

***

## 6. Integra√ß√£o com Sistema Existente

### 6.1 Pontos de Integra√ß√£o

#### 6.1.1 Firebase Firestore

```javascript
// Estrutura de dados simplificada para agente LLM
const llmTicket = {
  id: 'ticket_123',
  agentId: 'llm_principal',
  status: 'processing',
  priority: 'high',
  category: 'technical',
  messages: [
    {
      id: 'msg_1',
      content: 'Problema com login',
      sender: 'client',
      timestamp: new Date(),
      processed: false
    }
  ],
  llmProcessing: {
    classification: {
      category: 'technical',
      priority: 'high',
      confidence: 0.95
    },
    response: {
      generated: true,
      content: 'Vou te ajudar com o problema de login...',
      timestamp: new Date()
    },
    escalation: {
      required: false,
      reason: null
    }
  }
}
```

#### 6.1.2 Evolution API Webhooks

```javascript
// Webhook simplificado para agente LLM
app.post('/webhook/evolution/message', async (req, res) => {
  const { data } = req.body;
  
  // Extrair informa√ß√µes da mensagem
  const messageData = {
    remoteJid: data.key.remoteJid,
    messageId: data.key.id,
    content: data.message.conversation || data.message.extendedTextMessage?.text,
    timestamp: new Date(data.messageTimestamp * 1000)
  };
  
  // Processar diretamente com agente LLM
  const llmResponse = await llmAgent.processMessage(messageData);
  
  // Enviar resposta se gerada
  if (llmResponse.shouldRespond) {
    await evolutionAPI.sendMessage({
      remoteJid: messageData.remoteJid,
      message: llmResponse.content
    });
  }
  
  // Salvar no Firebase
  await firebaseService.saveProcessedMessage(messageData, llmResponse);
  
  res.status(200).json({ success: true });
});
```

### 6.2 Configura√ß√£o de Webhooks

#### 6.2.1 Eventos Monitorados

* **messages.upsert**: Nova mensagem recebida

* **messages.update**: Status de mensagem atualizado

* **chats.update**: Informa√ß√µes do chat atualizadas

#### 6.2.2 Configura√ß√£o no Evolution API

```bash
curl -X POST "http://localhost:8080/webhook/set/instance1" \
  -H "Content-Type: application/json" \
  -H "apikey: sua-api-key" \
  -d '{
    "url": "https://seu-crm.com/webhook/evolution",
    "events": [
      "messages.upsert",
      "messages.update",
      "chats.update"
    ]
  }'
```

***

## 7. Configura√ß√£o T√©cnica

### 7.1 Instala√ß√£o da Evo AI

#### 7.1.1 Clonagem do Reposit√≥rio

```bash
git clone https://github.com/EvolutionAPI/evo-ai.git
cd evo-ai
```

#### 7.1.2 Configura√ß√£o do Backend

```bash
# Criar ambiente virtual
make venv
source venv/bin/activate  # Linux/Mac
# ou no Windows: venv\Scripts\activate

# Instalar depend√™ncias
make install-dev
```

#### 7.1.3 Configura√ß√£o do Banco de Dados

```bash
# Aplicar migra√ß√µes
make alembic-upgrade

# Inserir dados iniciais
make seed-all
```

### 7.2 Vari√°veis de Ambiente

#### 7.2.1 Arquivo .env do Backend

```env
# Database settings
POSTGRES_CONNECTION_STRING="postgresql://postgres:password@localhost:5432/evo_ai"

# Redis settings
REDIS_HOST="localhost"
REDIS_PORT=6379
REDIS_PASSWORD=""

# AI Engine configuration
AI_ENGINE="adk"  # Options: "adk" or "crewai"

# JWT settings
JWT_SECRET_KEY="your-jwt-secret-key-here"

# Email provider configuration
EMAIL_PROVIDER="sendgrid"  # Options: "sendgrid" or "smtp"
SENDGRID_API_KEY="your-sendgrid-api-key"

# Encryption for API keys
ENCRYPTION_KEY="your-32-character-encryption-key"

# Langfuse integration
LANGFUSE_PUBLIC_KEY="pk-lf-your-public-key"
LANGFUSE_SECRET_KEY="sk-lf-your-secret-key"
OTEL_EXPORTER_OTLP_ENDPOINT="https://cloud.langfuse.com/api/public/otel"

# OpenAI API
OPENAI_API_KEY="sk-your-openai-api-key"

# Integration with existing CRM
CRM_API_URL="http://localhost:9004/api"
CRM_WEBHOOK_SECRET="your-webhook-secret"
FIREBASE_PROJECT_ID="cerc-3m1uep"
FIREBASE_SERVICE_ACCOUNT_KEY='{"type":"service_account",...}'
```

#### 7.2.2 Arquivo .env do Frontend

```env
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_WS_URL=ws://localhost:8000/ws
```

### 7.3 Configura√ß√£o dos Agentes

#### 7.3.1 Agente de Classifica√ß√£o

```python
# agents/classificacao_agent.py
from evo_ai import Agent, Tool

class ClassificacaoAgent(Agent):
    def __init__(self):
        super().__init__(
            name="AgentClassificacao",
            description="Especialista em classifica√ß√£o de tickets",
            model="gpt-4",
            temperature=0.1,
            max_tokens=500
        )
        
        self.system_prompt = """
        Voc√™ √© um especialista em classifica√ß√£o de tickets de suporte.
        
        Sua fun√ß√£o √© analisar mensagens de clientes e:
        1. Categorizar o tipo de problema
        2. Definir o n√≠vel de prioridade
        3. Identificar o departamento respons√°vel
        
        Categorias dispon√≠veis:
        - tecnico: Problemas de funcionamento
        - comercial: Quest√µes de vendas/cobran√ßa
        - suporte: D√∫vidas de uso
        - reclamacao: Insatisfa√ß√£o com servi√ßo
        - elogio: Feedback positivo
        
        Prioridades:
        - critica: Sistema fora do ar
        - alta: Funcionalidade importante afetada
        - media: Problema que pode aguardar
        - baixa: D√∫vidas gerais
        
        Responda sempre em formato JSON:
        {
          "categoria": "categoria_identificada",
          "prioridade": "nivel_prioridade",
          "departamento": "departamento_responsavel",
          "confianca": 0.95,
          "justificativa": "Explica√ß√£o da classifica√ß√£o"
        }
        """
        
        self.add_tool(self.categorizar_ticket)
    
    @Tool
    def categorizar_ticket(self, mensagem: str) -> dict:
        """Classifica um ticket baseado na mensagem do cliente"""
        # L√≥gica de classifica√ß√£o usando LLM
        response = self.llm.invoke(
            f"Classifique esta mensagem: {mensagem}"
        )
        return response
```

#### 7.3.2 Processamento Simplificado com LLM

```python
# agents/llm_agent.py
from evo_ai import Agent
import json

class LLMAgent(Agent):
    def __init__(self):
        super().__init__(
            name="AgenteLLMPrincipal",
            description="Agente principal para atendimento ao cliente",
            model="gpt-4",
            temperature=0.3,
            max_tokens=1000
        )
        
        self.system_prompt = """
        Voc√™ √© um assistente de atendimento ao cliente especializado.
        
        Suas responsabilidades:
        1. Classificar a mensagem por categoria e prioridade
        2. Gerar uma resposta √∫til e contextual
        3. Decidir se o caso precisa ser escalado
        4. Sugerir follow-ups quando apropriado
        
        Sempre responda em formato JSON com:
        {
          "classification": {
            "category": "categoria",
            "priority": "prioridade",
            "confidence": 0.95
          },
          "response": {
            "content": "resposta para o cliente",
            "should_send": true
          },
          "escalation": {
            "required": false,
            "reason": "motivo se necess√°rio"
          },
          "follow_up": {
            "needed": false,
            "when": "timing se necess√°rio"
          }
        }
        """
    
    async def process_message(self, message_data: dict) -> dict:
        """Processa uma mensagem completa"""
        prompt = f"""
        Mensagem do cliente: {message_data['content']}
        Cliente: {message_data.get('remoteJid', 'Desconhecido')}
        Timestamp: {message_data.get('timestamp', 'Agora')}
        
        Processe esta mensagem seguindo suas instru√ß√µes.
        """
        
        response = await self.llm.ainvoke(prompt)
        
        try:
            result = json.loads(response.content)
            return result
        except json.JSONDecodeError:
            # Fallback se o JSON estiver malformado
            return {
                "classification": {"category": "geral", "priority": "media", "confidence": 0.5},
                "response": {"content": response.content, "should_send": True},
                "escalation": {"required": False, "reason": None},
                "follow_up": {"needed": False, "when": None}
            }
```

***

## 8. Exemplos de C√≥digo

### 8.1 Integra√ß√£o com Firebase

#### 8.1.1 Servi√ßo de Integra√ß√£o

```typescript
// services/evo-ai-integration.ts
import { firebaseService } from './firebase-service';
import { EvoAIClient } from './evo-ai-client';

export class EvoAIIntegrationService {
  private evoAI: EvoAIClient;
  
  constructor() {
    this.evoAI = new EvoAIClient({
      baseUrl: process.env.EVO_AI_API_URL,
      apiKey: process.env.EVO_AI_API_KEY
    });
  }
  
  async processNewMessage(messageData: any) {
    try {
      // 1. Salvar mensagem no Firebase
      const messageId = await firebaseService.saveMessage(messageData);
      
      // 2. Enviar para Evo AI
      const result = await this.evoAI.processMessage({
        id: messageId,
        content: messageData.content,
        remoteJid: messageData.remoteJid,
        timestamp: messageData.timestamp
      });
      
      // 3. Processar resposta
      if (result.response) {
        await this.sendResponse(messageData.remoteJid, result.response);
      }
      
      // 4. Atualizar ticket
      await this.updateTicketWithAIResult(messageId, result);
      
      return result;
    } catch (error) {
      console.error('Erro no processamento:', error);
      throw error;
    }
  }
  
  private async sendResponse(remoteJid: string, response: string) {
    // Enviar resposta via Evolution API
    const evolutionAPI = new EvolutionAPIClient();
    await evolutionAPI.sendMessage({
      remoteJid,
      message: response
    });
  }
  
  private async updateTicketWithAIResult(messageId: string, result: any) {
    await firebaseService.updateDocument('messages', messageId, {
      aiProcessed: true,
      aiResult: result,
      category: result.category,
      priority: result.priority,
      updatedAt: new Date()
    });
  }
}
```

#### 8.1.2 Cliente Evo AI

```typescript
// services/evo-ai-client.ts
export class EvoAIClient {
  private baseUrl: string;
  private apiKey: string;
  
  constructor(config: { baseUrl: string; apiKey: string }) {
    this.baseUrl = config.baseUrl;
    this.apiKey = config.apiKey;
  }
  
  async processMessage(messageData: any) {
    const response = await fetch(`${this.baseUrl}/api/v1/process`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`
      },
      body: JSON.stringify({
        workflow: 'main_workflow',
        input: messageData
      })
    });
    
    if (!response.ok) {
      throw new Error(`Erro na API: ${response.statusText}`);
    }
    
    return await response.json();
  }
  
  async createAgent(agentConfig: any) {
    const response = await fetch(`${this.baseUrl}/api/v1/agents`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`
      },
      body: JSON.stringify(agentConfig)
    });
    
    return await response.json();
  }
  
  async getMetrics(timeRange: string = '24h') {
    const response = await fetch(
      `${this.baseUrl}/api/v1/metrics?range=${timeRange}`,
      {
        headers: {
          'Authorization': `Bearer ${this.apiKey}`
        }
      }
    );
    
    return await response.json();
  }
}
```

### 8.2 Webhook Handler

```typescript
// api/webhooks/evo-ai/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { EvoAIIntegrationService } from '@/services/evo-ai-integration';

const evoAIService = new EvoAIIntegrationService();

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    
    // Verificar assinatura do webhook
    const signature = request.headers.get('x-evo-signature');
    if (!verifyWebhookSignature(body, signature)) {
      return NextResponse.json(
        { error: 'Invalid signature' },
        { status: 401 }
      );
    }
    
    // Processar evento
    switch (body.event) {
      case 'agent.response':
        await handleAgentResponse(body.data);
        break;
        
      case 'workflow.completed':
        await handleWorkflowCompleted(body.data);
        break;
        
      case 'escalation.required':
        await handleEscalationRequired(body.data);
        break;
        
      default:
        console.log('Evento n√£o reconhecido:', body.event);
    }
    
    return NextResponse.json({ success: true });
  } catch (error) {
    console.error('Erro no webhook:', error);
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    );
  }
}

async function handleAgentResponse(data: any) {
  // Enviar resposta para o cliente
  const evolutionAPI = new EvolutionAPIClient();
  await evolutionAPI.sendMessage({
    remoteJid: data.remoteJid,
    message: data.response
  });
  
  // Atualizar Firebase
  await firebaseService.updateMessage(data.messageId, {
    aiResponse: data.response,
    status: 'responded',
    respondedAt: new Date()
  });
}

async function handleWorkflowCompleted(data: any) {
  // Atualizar status do ticket
  await firebaseService.updateTicket(data.ticketId, {
    status: data.resolved ? 'resolved' : 'pending',
    aiProcessingCompleted: true,
    completedAt: new Date()
  });
}

async function handleEscalationRequired(data: any) {
  // Notificar agentes humanos
  await notificationService.notifyAgents({
    ticketId: data.ticketId,
    priority: data.priority,
    reason: data.escalationReason,
    context: data.context
  });
}
```

***

## 9. Cronograma de Implementa√ß√£o

### 9.1 Vis√£o Geral Simplificada (6 semanas)

| Fase       | Dura√ß√£o   | Atividades Principais           | Entreg√°veis              |
| ---------- | --------- | ------------------------------- | ------------------------ |
| **Fase 1** | 1 semana  | Setup e Configura√ß√£o B√°sica    | Ambiente configurado     |
| **Fase 2** | 2 semanas | Desenvolvimento do Agente LLM  | Agente LLM funcional     |
| **Fase 3** | 1 semana  | Integra√ß√£o com CRM             | Sistema integrado        |
| **Fase 4** | 1 semana  | Testes e Refinamento           | Sistema testado          |
| **Fase 5** | 1 semana  | Deploy e Monitoramento         | Sistema em produ√ß√£o      |

### 9.2 Detalhamento por Fase

#### 9.2.1 Fase 1: Setup e Configura√ß√£o B√°sica (Semana 1)

**Atividades:**

* [ ] Instala√ß√£o da plataforma Evo AI
* [ ] Configura√ß√£o do ambiente de desenvolvimento
* [ ] Setup b√°sico do PostgreSQL (opcional)
* [ ] Configura√ß√£o das vari√°veis de ambiente
* [ ] Teste de conectividade com APIs (OpenAI, Firebase, Evolution)
* [ ] Setup da integra√ß√£o com Firebase
* [ ] Configura√ß√£o b√°sica dos webhooks

**Entreg√°veis:**

* Ambiente Evo AI funcional
* Conectividade com APIs confirmada
* Firebase integrado

#### 9.2.2 Fase 2: Desenvolvimento do Agente LLM (Semanas 2-3)

**Semana 2:**

* [ ] Desenvolvimento do agente LLM principal
* [ ] Configura√ß√£o de prompts din√¢micos
* [ ] Implementa√ß√£o da l√≥gica de classifica√ß√£o
* [ ] Cria√ß√£o da base de conhecimento b√°sica

**Semana 3:**

* [ ] Implementa√ß√£o da gera√ß√£o de respostas
* [ ] Sistema de escala√ß√£o autom√°tica
* [ ] Testes unit√°rios do agente
* [ ] Refinamento dos prompts

**Entreg√°veis:**

* Agente LLM funcional e testado
* Base de conhecimento inicial
* Sistema de prompts configur√°vel
* Testes unit√°rios aprovados

#### 9.2.3 Fase 3: Integra√ß√£o com CRM (Semana 4)

**Atividades:**

* [ ] Integra√ß√£o completa com Firebase Firestore
* [ ] Integra√ß√£o com Evolution API
* [ ] Implementa√ß√£o dos webhooks funcionais
* [ ] Sincroniza√ß√£o de dados em tempo real
* [ ] Sistema de notifica√ß√µes b√°sico
* [ ] Testes de fluxo completo

**Entreg√°veis:**

* Sistema totalmente integrado
* Webhooks funcionais
* Fluxo end-to-end operacional

#### 9.2.4 Fase 4: Testes e Refinamento (Semana 5)

**Atividades:**

* [ ] Testes de cen√°rios reais
* [ ] Ajustes nos prompts do agente
* [ ] Otimiza√ß√£o de performance
* [ ] Testes de seguran√ßa b√°sicos
* [ ] Valida√ß√£o com usu√°rios finais
* [ ] Corre√ß√£o de bugs identificados

**Entreg√°veis:**

* Sistema testado e validado
* Prompts otimizados
* Bugs corrigidos
* Documenta√ß√£o atualizada

* Documenta√ß√£o atualizada

#### 9.2.5 Fase 5: Deploy e Monitoramento (Semana 6)

**Atividades:**

* [ ] Deploy em ambiente de produ√ß√£o
* [ ] Configura√ß√£o de monitoramento b√°sico
* [ ] Setup de alertas essenciais
* [ ] Treinamento da equipe
* [ ] Monitoramento inicial
* [ ] Ajustes p√≥s-deploy
* [ ] Documenta√ß√£o de opera√ß√£o

**Entreg√°veis:**

* Sistema em produ√ß√£o
* Monitoramento ativo
* Equipe treinada
* Documenta√ß√£o operacional

### 9.3 Marcos Importantes Simplificados

* **Marco 1** (Semana 1): Ambiente configurado
* **Marco 2** (Semana 3): Agente LLM desenvolvido
* **Marco 3** (Semana 4): Sistema integrado
* **Marco 4** (Semana 5): Testes conclu√≠dos
* **Marco 5** (Semana 6): Sistema em produ√ß√£o

### 9.4 Recursos Necess√°rios Simplificados

#### 9.4.1 Equipe M√≠nima

* **1 Desenvolvedor Senior**: Arquitetura, integra√ß√£o e desenvolvimento do agente LLM
* **1 DevOps** (opcional): Deploy e infraestrutura b√°sica

#### 9.4.2 Infraestrutura B√°sica

* **Servidor de desenvolvimento**: 4GB RAM, 2 cores
* **Servidor de produ√ß√£o**: 8GB RAM, 4 cores
* **Firebase**: Banco de dados principal (j√° existente)
* **PostgreSQL**: Opcional para Evo AI (pode usar SQLite inicialmente)

***

## 10. Deployment e Infraestrutura

### 10.1 Arquitetura de Deploy

```mermaid
graph TB
    subgraph "Load Balancer"
        LB[Nginx/HAProxy]
    end
    
    subgraph "Application Layer"
        APP1[Evo AI Instance 1]
        APP2[Evo AI Instance 2]
        APP3[Evo AI Instance 3]
    end
    
    subgraph "Database Layer"
        PG[(PostgreSQL Primary)]
        PGR[(PostgreSQL Replica)]
        RD[(Redis Cluster)]
    end
    
    subgraph "Monitoring"
        PROM[Prometheus]
        GRAF[Grafana]
        LF[Langfuse]
    end
    
    LB --> APP1
    LB --> APP2
    LB --> APP3
    
    APP1 --> PG
    APP2 --> PG
    APP3 --> PG
    
    PG --> PGR
    
    APP1 --> RD
    APP2 --> RD
    APP3 --> RD
    
    APP1 --> LF
    APP2 --> LF
    APP3 --> LF
    
    PROM --> GRAF
```

### 10.2 Docker Configuration

#### 10.2.1 Dockerfile para Evo AI

```dockerfile
# Dockerfile.evo-ai
FROM python:3.11-slim

# Instalar depend√™ncias do sistema
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    make \
    && rm -rf /var/lib/apt/lists/*

# Criar usu√°rio n√£o-root
RUN useradd -m -u 1000 evoai

# Definir diret√≥rio de trabalho
WORKDIR /app

# Copiar requirements
COPY requirements.txt .

# Instalar depend√™ncias Python
RUN pip install --no-cache-dir -r requirements.txt

# Copiar c√≥digo da aplica√ß√£o
COPY . .

# Mudar ownership para usu√°rio n√£o-root
RUN chown -R evoai:evoai /app

# Mudar para usu√°rio n√£o-root
USER evoai

# Expor porta
EXPOSE 8000

# Comando de inicializa√ß√£o
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 10.2.2 Docker Compose

```yaml
# docker-compose.yml
version: '3.8'

services:
  evo-ai:
    build:
      context: .
      dockerfile: Dockerfile.evo-ai
    ports:
      - "8000:8000"
    environment:
      - POSTGRES_CONNECTION_STRING=postgresql://postgres:password@postgres:5432/evo_ai
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - postgres
      - redis
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    
  postgres:
    image: postgres:15
    environment:
      - POSTGRES_DB=evo_ai
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    restart: unless-stopped
    
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - evo-ai
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
```

### 10.3 Configura√ß√£o do Nginx

```nginx
# nginx.conf
events {
    worker_connections 1024;
}

http {
    upstream evo_ai {
        server evo-ai:8000;
    }
    
    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    
    server {
        listen 80;
        server_name seu-dominio.com;
        
        # Redirect HTTP to HTTPS
        return 301 https://$server_name$request_uri;
    }
    
    server {
        listen 443 ssl http2;
        server_name seu-dominio.com;
        
        # SSL Configuration
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers HIGH:!aNULL:!MD5;
        
        # Security headers
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        
        # API routes
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            
            proxy_pass http://evo_ai;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Timeouts
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
        }
        
        # WebSocket support
        location /ws/ {
            proxy_pass http://evo_ai;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
        }
        
        # Health check
        location /health {
            proxy_pass http://evo_ai/health;
        }
    }
}
```

### 10.4 Scripts de Deploy

#### 10.4.1 Script de Deploy Automatizado

```bash
#!/bin/bash
# deploy.sh

set -e

echo "üöÄ Iniciando deploy do Evo AI..."

# Vari√°veis
APP_NAME="evo-ai"
DOCKER_IMAGE="$APP_NAME:latest"
BACKUP_DIR="/backups"
DATE=$(date +%Y%m%d_%H%M%S)

# Fun√ß√£o de rollback
rollback() {
    echo "‚ùå Erro detectado. Iniciando rollback..."
    docker-compose down
    docker-compose -f docker-compose.backup.yml up -d
    echo "‚úÖ Rollback conclu√≠do"
    exit 1
}

# Trap para capturar erros
trap rollback ERR

# 1. Backup do banco de dados
echo "üì¶ Criando backup do banco..."
mkdir -p $BACKUP_DIR
docker exec postgres pg_dump -U postgres evo_ai > "$BACKUP_DIR/evo_ai_$DATE.sql"

# 2. Backup da configura√ß√£o atual
echo "üì¶ Backup da configura√ß√£o..."
cp docker-compose.yml docker-compose.backup.yml

# 3. Pull da nova imagem
echo "üì• Baixando nova vers√£o..."
docker-compose pull

# 4. Build se necess√°rio
echo "üî® Building aplica√ß√£o..."
docker-compose build

# 5. Parar servi√ßos
echo "‚èπÔ∏è Parando servi√ßos..."
docker-compose down

# 6. Aplicar migra√ß√µes
echo "üîÑ Aplicando migra√ß√µes..."
docker-compose run --rm evo-ai alembic upgrade head

# 7. Iniciar servi√ßos
echo "‚ñ∂Ô∏è Iniciando servi√ßos..."
docker-compose up -d

# 8. Health check
echo "üè• Verificando sa√∫de da aplica√ß√£o..."
sleep 30

for i in {1..10}; do
    if curl -f http://localhost:8000/health; then
        echo "‚úÖ Aplica√ß√£o est√° saud√°vel"
        break
    else
        echo "‚è≥ Aguardando aplica√ß√£o... ($i/10)"
        sleep 10
    fi
    
    if [ $i -eq 10 ]; then
        echo "‚ùå Aplica√ß√£o n√£o respondeu ao health check"
        rollback
    fi
done

# 9. Limpeza
echo "üßπ Limpando imagens antigas..."
docker image prune -f

echo "üéâ Deploy conclu√≠do com sucesso!"
```

#### 10.4.2 Script de Monitoramento

```bash
#!/bin/bash
# monitor.sh

# Verificar status dos servi√ßos
check_services() {
    echo "üìä Status dos servi√ßos:"
    docker-compose ps
}

# Verificar logs de erro
check_logs() {
    echo "üìã √öltimos logs de erro:"
    docker-compose logs --tail=50 evo-ai | grep -i error
}

# Verificar m√©tricas de performance
check_performance() {
    echo "‚ö° M√©tricas de performance:"
    
    # CPU e Mem√≥ria
    docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"
    
    # Conex√µes do banco
    echo "\nüóÑÔ∏è Conex√µes do PostgreSQL:"
    docker exec postgres psql -U postgres -d evo_ai -c "SELECT count(*) as active_connections FROM pg_stat_activity WHERE state = 'active';"
    
    # Cache Redis
    echo "\nüíæ Estat√≠sticas do Redis:"
    docker exec redis redis-cli info stats | grep -E "(keyspace_hits|keyspace_misses|used_memory_human)"
}

# Verificar espa√ßo em disco
check_disk() {
    echo "üíø Espa√ßo em disco:"
    df -h
}

# Executar todas as verifica√ß√µes
echo "üîç Iniciando monitoramento..."
check_services
echo "\n"
check_performance
echo "\n"
check_disk
echo "\n"
check_logs
```

### 10.5 Configura√ß√£o de CI/CD

#### 10.5.1 GitHub Actions

```yaml
# .github/workflows/deploy.yml
name: Deploy Evo AI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: evo_ai_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov
    
    - name: Run tests
      env:
        POSTGRES_CONNECTION_STRING: postgresql://postgres:postgres@localhost:5432/evo_ai_test
        REDIS_HOST: localhost
        REDIS_PORT: 6379
      run: |
        pytest tests/ -v --cov=app --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
  
  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Deploy to production
      uses: appleboy/ssh-action@v0.1.5
      with:
        host: ${{ secrets.HOST }}
        username: ${{ secrets.USERNAME }}
        key: ${{ secrets.SSH_KEY }}
        script: |
          cd /opt/evo-ai
          git pull origin main
          ./deploy.sh
```

***

## 11. Monitoramento e M√©tricas

### 11.1 M√©tricas de Performance

#### 11.1.1 M√©tricas dos Agentes

| M√©trica                       | Descri√ß√£o                               | Meta  | Alerta |
| ----------------------------- | --------------------------------------- | ----- | ------ |
| **Tempo de Resposta**         | Tempo m√©dio para primeira resposta      | < 30s | > 60s  |
| **Taxa de Resolu√ß√£o**         | % de tickets resolvidos automaticamente | > 40% | < 30%  |
| **Precis√£o de Classifica√ß√£o** | % de classifica√ß√µes corretas            | > 85% | < 80%  |
| **Taxa de Escala√ß√£o**         | % de tickets escalados                  | < 20% | > 30%  |
| **Satisfa√ß√£o do Cliente**     | NPS m√©dio                               | > 8.0 | < 7.0  |

#### 11.1.2 M√©tricas de Sistema

| M√©trica             | Descri√ß√£o                    | Meta    | Alerta  |
| ------------------- | ---------------------------- | ------- | ------- |
| **Uptime**          | Disponibilidade do sistema   | > 99.5% | < 99%   |
| **Lat√™ncia da API** | Tempo de resposta da API     | < 200ms | > 500ms |
| **Throughput**      | Mensagens processadas/minuto | > 100   | < 50    |
| **Uso de CPU**      | Utiliza√ß√£o m√©dia de CPU      | < 70%   | > 85%   |
| **Uso de Mem√≥ria**  | Utiliza√ß√£o de RAM            | < 80%   | > 90%   |

### 11.2 Dashboard de Monitoramento

#### 11.2.1 Configura√ß√£o do Prometheus

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'evo-ai'
    static_configs:
      - targets: ['evo-ai:8000']
    metrics_path: '/metrics'
    scrape_interval: 10s
    
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']
    
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
    
  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx-exporter:9113']
```

#### 11.2.2 Alertas do Prometheus

```yaml
# alert_rules.yml
groups:
- name: evo-ai-alerts
  rules:
  - alert: HighResponseTime
    expr: avg(evo_ai_response_time_seconds) > 60
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Tempo de resposta alto"
      description: "Tempo m√©dio de resposta est√° acima de 60 segundos"
      
  - alert: LowResolutionRate
    expr: (evo_ai_resolved_tickets / evo_ai_total_tickets) * 100 < 30
    for: 10m
    labels:
      severity: critical
    annotations:
      summary: "Taxa de resolu√ß√£o baixa"
      description: "Taxa de resolu√ß√£o autom√°tica est√° abaixo de 30%"
      
  - alert: HighErrorRate
    expr: rate(evo_ai_errors_total[5m]) > 0.1
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "Taxa de erro alta"
      description: "Taxa de erro est√° acima de 10%"
      
  - alert: DatabaseConnectionsHigh
    expr: pg_stat_database_numbackends > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Muitas conex√µes no banco"
      description: "N√∫mero de conex√µes no PostgreSQL est√° alto"
```

#### 11.2.3 Dashboard Grafana

```json
{
  "dashboard": {
    "title": "Evo AI - Monitoramento",
    "panels": [
      {
        "title": "Tempo de Resposta dos Agentes",
        "type": "graph",
        "targets": [
          {
            "expr": "avg(evo_ai_agent_response_time_seconds) by (agent_type)",
            "legendFormat": "{{agent_type}}"
          }
        ]
      },
      {
        "title": "Taxa de Resolu√ß√£o por Categoria",
        "type": "piechart",
        "targets": [
          {
            "expr": "sum(evo_ai_resolved_tickets) by (category)",
            "legendFormat": "{{category}}"
          }
        ]
      },
      {
        "title": "Throughput de Mensagens",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(evo_ai_messages_processed_total[5m]) * 60",
            "legendFormat": "Mensagens/minuto"
          }
        ]
      },
      {
        "title": "Status dos Agentes",
        "type": "stat",
        "targets": [
          {
            "expr": "evo_ai_agents_active",
            "legendFormat": "Agentes Ativos"
          }
        ]
      }
    ]
  }
}
```

### 11.3 Logging e Observabilidade

#### 11.3.1 Configura√ß√£o de Logs

```python
# logging_config.py
import logging
import sys
from pythonjsonlogger import jsonlogger

def setup_logging():
    # Configurar formato JSON para logs
    logHandler = logging.StreamHandler(sys.stdout)
    formatter = jsonlogger.JsonFormatter(
        fmt='%(asctime)s %(name)s %(levelname)s %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    logHandler.setFormatter(formatter)
    
    # Configurar logger principal
    logger = logging.getLogger('evo_ai')
    logger.setLevel(logging.INFO)
    logger.addHandler(logHandler)
    
    return logger

# Exemplo de uso em agentes
class AgentLogger:
    def __init__(self, agent_name: str):
        self.logger = logging.getLogger(f'evo_ai.{agent_name}')
    
    def log_processing(self, message_id: str, action: str, result: dict):
        self.logger.info(
            "Agent processing",
            extra={
                "message_id": message_id,
                "agent_action": action,
                "result": result,
                "timestamp": datetime.utcnow().isoformat()
            }
        )
```

#### 11.3.2 Integra√ß√£o com Langfuse
```python
# langfuse_integration.py
from langfuse import Langfuse
from langfuse.decorators import observe

langfuse = Langfuse(
    public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
    secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
    host=os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com")
)

class AgentTracer:
    def __init__(self, agent_name: str):
        self.agent_name = agent_name
    
    @observe()
    def trace_agent_execution(self, input_data: dict, output_data: dict):
        """Rastrear execu√ß√£o do agente"""
        trace = langfuse.trace(
            name=f"{self.agent_name}_execution",
            input=input_data,
            output=output_data,
            metadata={
                "agent_type": self.agent_name,
                "timestamp": datetime.utcnow().isoformat()
            }
        )
        return trace
```

---

## 12. Casos de Uso Pr√°ticos

### 12.1 Cen√°rio 1: Cliente com Problema T√©cnico

#### 12.1.1 Fluxo do Processo
```
Cliente: "N√£o consigo fazer login no sistema"
‚Üì
Agente Classifica√ß√£o: Categoria="tecnico", Prioridade="media"
‚Üì
Agente Atendimento: Busca na base de conhecimento
‚Üì
Resposta: "Vamos resolver isso! Primeiro, tente limpar o cache..."
‚Üì
Se n√£o resolver ‚Üí Escala√ß√£o para suporte t√©cnico
```

#### 12.1.2 Exemplo de Resposta
```json
{
  "agent_response": {
    "message": "Ol√°! Entendo que voc√™ est√° com dificuldades para fazer login. Vou te ajudar a resolver isso passo a passo:\n\n1Ô∏è‚É£ **Limpe o cache do navegador**\n2Ô∏è‚É£ **Verifique se o Caps Lock est√° desligado**\n3Ô∏è‚É£ **Tente usar a op√ß√£o 'Esqueci minha senha'**\n\nSe ainda n√£o funcionar, posso te conectar com nossa equipe t√©cnica. Voc√™ gostaria de tentar essas solu√ß√µes primeiro?",
    "category": "tecnico",
    "priority": "media",
    "next_actions": ["aguardar_resposta", "escalar_se_necessario"],
    "estimated_resolution_time": "5-10 minutos"
  }
}
```

### 12.2 Cen√°rio 2: Cliente VIP com Reclama√ß√£o

#### 12.1.1 Fluxo Priorit√°rio
```
Cliente VIP: "Estou muito insatisfeito com o atendimento"
‚Üì
Agente Classifica√ß√£o: Categoria="reclamacao", Prioridade="critica"
‚Üì
Escala√ß√£o Imediata: Notifica gerente de contas
‚Üì
Agente Humano: Assume o atendimento em < 2 minutos
```

### 12.3 Cen√°rio 3: Pergunta Comercial

#### 12.3.1 Fluxo de Vendas
```
Cliente: "Quais s√£o os planos dispon√≠veis?"
‚Üì
Agente Classifica√ß√£o: Categoria="comercial", Prioridade="media"
‚Üì
Agente Atendimento: Apresenta op√ß√µes de planos
‚Üì
Follow-up: Agenda contato comercial se interessado
```

---

## 13. Troubleshooting e FAQ

### 13.1 Problemas Comuns

#### 13.1.1 Agente n√£o responde

**Sintomas:**
- Mensagens ficam sem resposta
- Status "processing" por muito tempo

**Diagn√≥stico:**
```bash
# Verificar logs do agente
docker logs evo-ai | grep ERROR

# Verificar conex√£o com LLM
curl -X POST "http://localhost:8000/api/v1/health/llm"

# Verificar fila de processamento
redis-cli LLEN message_queue
```

**Solu√ß√µes:**
1. Reiniciar servi√ßo do agente
2. Verificar chave da API do LLM
3. Limpar fila do Redis se necess√°rio

#### 13.1.2 Classifica√ß√£o incorreta

**Sintomas:**
- Tickets categorizados erroneamente
- Escala√ß√µes desnecess√°rias

**Diagn√≥stico:**
```python
# Verificar hist√≥rico de classifica√ß√µes
from evo_ai.analytics import ClassificationAnalyzer

analyzer = ClassificationAnalyzer()
accuracy = analyzer.get_accuracy_last_24h()
print(f"Precis√£o: {accuracy}%")
```

**Solu√ß√µes:**
1. Ajustar prompts do agente de classifica√ß√£o
2. Adicionar exemplos √† base de conhecimento
3. Retreinar modelo se necess√°rio

#### 13.1.3 Performance lenta

**Sintomas:**
- Tempo de resposta > 60 segundos
- Timeouts frequentes

**Diagn√≥stico:**
```bash
# Verificar recursos do sistema
docker stats

# Verificar lat√™ncia da API
curl -w "@curl-format.txt" -s -o /dev/null http://localhost:8000/api/v1/health

# Verificar conex√µes do banco
psql -c "SELECT count(*) FROM pg_stat_activity;"
```

**Solu√ß√µes:**
1. Aumentar recursos (CPU/RAM)
2. Otimizar queries do banco
3. Implementar cache adicional
4. Escalar horizontalmente

### 13.2 FAQ T√©cnico

#### Q: Como adicionar um novo tipo de agente?
**A:** 
1. Criar classe do agente em `agents/`
2. Registrar no workflow principal
3. Adicionar configura√ß√£o no banco
4. Testar integra√ß√£o

#### Q: Como modificar prompts dos agentes?
**A:**
1. Acessar interface admin: `http://localhost:8000/admin`
2. Navegar para "Agent Configurations"
3. Editar prompt do agente desejado
4. Salvar e testar

#### Q: Como fazer backup dos dados?
**A:**
```bash
# Backup do PostgreSQL
pg_dump -U postgres evo_ai > backup_$(date +%Y%m%d).sql

# Backup do Redis
redis-cli BGSAVE
cp /var/lib/redis/dump.rdb backup_redis_$(date +%Y%m%d).rdb
```

#### Q: Como escalar o sistema?
**A:**
1. **Horizontal**: Adicionar mais inst√¢ncias do Evo AI
2. **Vertical**: Aumentar recursos das inst√¢ncias existentes
3. **Database**: Implementar read replicas
4. **Cache**: Usar Redis Cluster

---

## 14. Considera√ß√µes de Escalabilidade

### 14.1 Arquitetura Escal√°vel

#### 14.1.1 Microservi√ßos
```mermaid
graph TB
    subgraph "Load Balancer"
        LB[HAProxy/Nginx]
    end
    
    subgraph "Agent Services"
        AC[Classifica√ß√£o Service]
        AA[Atendimento Service]
        AE[Escala√ß√£o Service]
        AF[Follow-up Service]
    end
    
    subgraph "Shared Services"
        WF[Workflow Orchestrator]
        KB[Knowledge Base API]
        NT[Notification Service]
    end
    
    subgraph "Data Layer"
        PG[(PostgreSQL Cluster)]
        RD[(Redis Cluster)]
        ES[(Elasticsearch)]
    end
    
    LB --> AC
    LB --> AA
    LB --> AE
    LB --> AF
    
    AC --> WF
    AA --> WF
    AE --> WF
    AF --> WF
    
    WF --> KB
    WF --> NT
    
    AC --> PG
    AA --> PG
    AE --> PG
    AF --> PG
    
    AC --> RD
    AA --> RD
    AE --> RD
    AF --> RD
    
    KB --> ES
```

#### 14.1.2 Estrat√©gias de Escalabilidade

**1. Escalabilidade Horizontal**
- **Auto Scaling**: Baseado em CPU/mem√≥ria
- **Load Balancing**: Distribui√ß√£o de carga
- **Service Mesh**: Istio para comunica√ß√£o

**2. Otimiza√ß√£o de Performance**
- **Connection Pooling**: PgBouncer para PostgreSQL
- **Caching Strategy**: Multi-layer cache
- **Async Processing**: Celery para tarefas pesadas

**3. Particionamento de Dados**
```sql
-- Particionamento por data
CREATE TABLE messages_2024_01 PARTITION OF messages
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE messages_2024_02 PARTITION OF messages
FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
```

### 14.2 M√©tricas de Capacidade

| M√©trica | Atual | Meta 6 meses | Meta 1 ano |
|---------|-------|--------------|------------|
| **Mensagens/dia** | 1.000 | 10.000 | 50.000 |
| **Agentes simult√¢neos** | 4 | 20 | 100 |
| **Tempo de resposta** | 30s | 15s | 10s |
| **Uptime** | 99.5% | 99.9% | 99.95% |

### 14.3 Plano de Crescimento

#### 14.3.1 Fase 1: Otimiza√ß√£o (Meses 1-3)
- Implementar cache L2
- Otimizar queries do banco
- Adicionar √≠ndices espec√≠ficos
- Configurar connection pooling

#### 14.3.2 Fase 2: Escalabilidade (Meses 4-6)
- Implementar auto-scaling
- Adicionar read replicas
- Migrar para microservi√ßos
- Implementar service mesh

#### 14.3.3 Fase 3: Alta Disponibilidade (Meses 7-12)
- Multi-region deployment
- Disaster recovery
- Zero-downtime deployments
- Advanced monitoring

---

## 15. Roadmap Futuro

### 15.1 Pr√≥ximas Funcionalidades (3 meses)

#### 15.1.1 Agentes Especializados
- **Agente de Vendas**: Qualifica√ß√£o de leads
- **Agente de Reten√ß√£o**: Preven√ß√£o de churn
- **Agente Multil√≠ngue**: Suporte em m√∫ltiplos idiomas

#### 15.1.2 Integra√ß√µes Avan√ßadas
- **CRM Integration**: Salesforce, HubSpot
- **Voice Support**: Integra√ß√£o com telefonia
- **Video Chat**: Suporte por v√≠deo chamada

### 15.2 Melhorias de IA (6 meses)

#### 15.2.1 Modelos Customizados
- **Fine-tuning**: Modelos espec√≠ficos do dom√≠nio
- **RAG Avan√ßado**: Retrieval mais preciso
- **Multimodal**: Processamento de imagens/voz

#### 15.2.2 Automa√ß√£o Inteligente
- **Workflow Learning**: Aprendizado de padr√µes
- **Predictive Escalation**: Previs√£o de escala√ß√µes
- **Sentiment Analysis**: An√°lise de sentimento em tempo real

### 15.3 Expans√£o de Canais (9 meses)

#### 15.3.1 Novos Canais
- **Instagram**: Mensagens diretas
- **Telegram**: Bot integrado
- **Email**: Processamento autom√°tico
- **SMS**: Suporte via SMS

#### 15.3.2 Omnichannel
- **Unified Inbox**: Caixa de entrada unificada
- **Context Sharing**: Contexto entre canais
- **Seamless Handoff**: Transfer√™ncia suave

### 15.4 Analytics Avan√ßado (12 meses)

#### 15.4.1 Business Intelligence
- **Customer Journey**: Mapeamento da jornada
- **Predictive Analytics**: An√°lise preditiva
- **ROI Tracking**: Rastreamento de ROI

#### 15.4.2 Machine Learning
- **Churn Prediction**: Previs√£o de cancelamento
- **Upsell Opportunities**: Oportunidades de venda
- **Satisfaction Prediction**: Previs√£o de satisfa√ß√£o

### 15.5 Cronograma de Releases

```mermaid
gantt
    title Roadmap Evo AI - Pr√≥ximos 12 meses
    dateFormat  YYYY-MM-DD
    section Fase 1
    Agentes Especializados    :2024-02-01, 2024-04-30
    Integra√ß√µes CRM          :2024-03-01, 2024-05-31
    
    section Fase 2
    Modelos Customizados     :2024-05-01, 2024-07-31
    Automa√ß√£o Inteligente    :2024-06-01, 2024-08-31
    
    section Fase 3
    Novos Canais            :2024-08-01, 2024-10-31
    Omnichannel             :2024-09-01, 2024-11-30
    
    section Fase 4
    Business Intelligence    :2024-11-01, 2025-01-31
    Machine Learning        :2024-12-01, 2025-02-28
```

---

## Conclus√£o

Este plano de implementa√ß√£o fornece uma base s√≥lida para a cria√ß√£o de um sistema de agentes de IA robusto e escal√°vel. A combina√ß√£o da plataforma Evo AI com o sistema CRM existente permitir√°:

- **Automa√ß√£o inteligente** do atendimento ao cliente
- **Redu√ß√£o significativa** nos tempos de resposta
- **Melhoria na satisfa√ß√£o** do cliente
- **Otimiza√ß√£o dos recursos** da equipe de suporte
- **Escalabilidade** para crescimento futuro

O sucesso da implementa√ß√£o depender√° de:
1. **Execu√ß√£o rigorosa** do cronograma
2. **Monitoramento cont√≠nuo** das m√©tricas
3. **Ajustes baseados** em feedback real
4. **Treinamento adequado** da equipe
5. **Manuten√ß√£o proativa** do sistema

Com este plano detalhado, a organiza√ß√£o estar√° preparada para implementar uma solu√ß√£o de IA de classe mundial que transformar√° a experi√™ncia de atendimento ao cliente.

### üöÄ Expans√£o Futura

Esta implementa√ß√£o simplificada com agente LLM √∫nico serve como base s√≥lida para expans√µes futuras:

* **Agentes Especializados**: Adicionar agentes espec√≠ficos para classifica√ß√£o, escala√ß√£o e follow-up
* **Workflows Complexos**: Implementar LangGraph para fluxos mais sofisticados
* **Protocolo A2A**: Integrar comunica√ß√£o entre m√∫ltiplos agentes
* **An√°lise Avan√ßada**: Adicionar an√°lise de sentimento e m√©tricas detalhadas
* **Canais M√∫ltiplos**: Expandir para Instagram, Telegram, Email

---

## Conclus√£o

Este plano simplificado permite uma implementa√ß√£o r√°pida e eficaz de um sistema de IA para atendimento ao cliente, focando em:

- **Implementa√ß√£o em 6 semanas** com recursos m√≠nimos
- **Agente LLM √∫nico** que realiza todas as fun√ß√µes essenciais
- **Integra√ß√£o direta** com o sistema CRM existente
- **Base s√≥lida** para expans√µes futuras
- **ROI r√°pido** com funcionalidades essenciais

A abordagem simplificada reduz a complexidade inicial mantendo todas as funcionalidades core necess√°rias para automatizar o atendimento ao cliente de forma eficiente.

---

**Documento criado em:** Janeiro 2025
**Vers√£o:** 2.0 (Simplificada)
**Autor:** Equipe de Desenvolvimento IA
**Pr√≥xima revis√£o:** Fevereiro 2025
```

